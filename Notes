Current Tasks:
* check other values of epsilon min (lower values, 0.03, 0.05)
* check gamma values (0.10,0.05)
* try and change the batch size to update less frequently (every 200 rounds or something)
* test deeper and shallower architectures.

Thoughts and Ideas:
* regularization on every layer and not just last layer
* PREPROCESSING -- add features for distance from fruit for all fruits, up to radius distance.

TODOs:  (after current)

* if we're score_scope away from the end - stop exploration to maximize results
* all tests should be against 4 avoid agents


USEFUL SOURCES:
https://github.com/keon/deep-q-learning/blob/master/dqn.py
https://github.com/keon/deep-q-learning


changes made by ziv on wednesday night:
changed epsilon calculation
update to train happens every learn (instead of every 50)
batch threshold is much lower (100)
bigger deque (500)
t=0.5


RESULTS:
At Round 40800 the scores are:
Player 1: -0.0590
Player 2: 0.1526
Player 3: 0.0888
Player 4: -0.0016
Player 5: -0.0374
0::0:14:34	3	VALUE	Rewards in last 100 rounds: 3
0::0:14:34	1	VALUE	Rewards in last 100 rounds: 9
0::0:14:34	2	VALUE	Rewards in last 100 rounds: 5
0::0:14:34	4	VALUE	Rewards in last 100 rounds: 0
