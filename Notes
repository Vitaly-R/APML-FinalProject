Current Tasks:
* current custom is learning very slowly - why? how does each hyper parameter effect the result? can we limit the hyper
    parameters better? can we use more techniques?
* find the optimal hyperparameters



TODOs:  (after current)
* custom model - target update in learn - why do we use [0] instead of the index related to the state? what does the [0] represent?

* check values of q function -- does it reach nan values because it gets too big?

* find a way to use decay on learning rate while having constant MIN learning rate

* if we're score_scope away from the end - stop exploration to maximize results



USEFUL SOURCES:
https://github.com/keon/deep-q-learning/blob/master/dqn.py

https://github.com/keon/deep-q-learning

