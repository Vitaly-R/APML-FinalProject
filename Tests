---------- Tests over the custom policy with different architectures and parameters ----------
* All tests are over 10000 rounds against 4 Avoid policies with epsilon values of 0, 0.1667, 0.3333, 0.5

python snake.py -D 10000 -pat 0.01 -plt 0.05 -s 5000 -P "Avoid(epsilon=0);Avoid(epsilon=0.1667);Avoid(epsilon=0.3333);Avoid(epsilon=0.5);CustomPolicy(model=0)"

Round 1: (Shallow dense network)
    * Architecture: input -> dense -> output
    * other parameters: batch size = 20; radius = 5; threshold = 500
    Test 1 : Influence of size of neurons
        learning rate | gamma | epsilon decay | neurons in hidden layer | initial score | final score | reached positive?
        0.1             .15         0.9              64                     -0.56           -0.2028         no
        0.1             .15         0.9              256                    -0.43           -0.3112         no
        0.1             .15         0.9              1024                   -0.25           -0.2526         no

    Test 2 : Influence of epsilon decay
        learning rate | gamma | epsilon decay | neurons in hidden layer | initial score | final score | reached positive?
        0.1             .15         0.9              64                     -0.56           -0.2028         no
        0.1             .15         0.99             64                     -0.35           -0.1566         no
        0.1             .15         0.999            64                     -0.40           -0.1524         no

    Test 3 : Influence of gamma
        learning rate | gamma | epsilon decay | neurons in hidden layer | initial score | final score | reached positive?
        0.001             .15         0.999            64                     -0.23           -0.17         no
        0.001             .5          0.999            64                     -0.46           -0.21         no
        0.001             .85         0.999            64                     -0.51           -0.15         no
        0.01              .95         0.999            64                     -0.31           -0.2146       no
        0.0001            .95         0.999            64                     -0.06           -0.2990       no

    input -> dense(128, tanh) -> dense(128, tanh) -> dense(64, tanh) -> dense(64, tanh) -> output
        learning rate | gamma | epsilon decay | neurons in hidden layer | initial score | final score | reached positive?
        0.0001            .95         0.999            64                   -0.5            -0.1316


Round 2: (Convolutional network)
    * Architecture: inout -> conv2d (64, 3x3, tanh) -> conv2d (128, 3x3, tanh) -> dense (128, tanh) -> dense (128, tanh) -> output
        learning rate | gamma | epsilon decay  | initial score | final score | reached positive?
            0.001       0.95        0.999           -0.33           -0.2472         no
            0.001       0.5         0.999           -0.2            -0.3234         no

    * Architecture: inout -> conv2d (32, 5x5, tanh) -> conv2d (64, 3x3, tanh) -> dense (256, tanh) -> dense (128, tanh) -> output
        ** tested for 50000 rounds
        learning rate | gamma | epsilon decay  | initial score | final score | reached positive?
            0.001       0.95        0.999           -0.28           -0.2852         no